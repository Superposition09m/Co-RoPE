"""
Kernel è¯Šæ–­å·¥å…·ï¼šæ£€æŸ¥ register usage, occupancy ç­‰
ç”¨äºå®šä½é•¿åºåˆ—æ€§èƒ½é€€åŒ–çš„æ ¹æœ¬åŸå› 
"""

import torch
import triton

from fused_rope_attn import attention as fused_rope_attn
from flash_attn_v2_triton import attention as flash_attn_v2_triton
from rope_attn_pytorch import precompute_freqs_cis


def diagnose_kernel_config(seq_len, head_dim=128, batch=1, n_heads=32, causal=True):
    """
    è¯Šæ–­ç‰¹å®šåºåˆ—é•¿åº¦ä¸‹çš„ kernel é…ç½®
    
    Args:
        seq_len: åºåˆ—é•¿åº¦
        head_dim: head dimension
        batch: batch size
        n_heads: number of heads
        causal: causal masking
    """
    device = 'cuda'
    dtype = torch.float16
    
    print(f"\n{'='*80}")
    print(f"è¯Šæ–­åºåˆ—é•¿åº¦: N={seq_len}, D={head_dim}, B={batch}, H={n_heads}")
    print(f"{'='*80}")
    
    # å‡†å¤‡è¾“å…¥
    q = torch.randn(batch, n_heads, seq_len, head_dim, device=device, dtype=dtype)
    k = torch.randn(batch, n_heads, seq_len, head_dim, device=device, dtype=dtype)
    v = torch.randn(batch, n_heads, seq_len, head_dim, device=device, dtype=dtype)
    freqs_cos, freqs_sin = precompute_freqs_cis(head_dim, seq_len, device=device)
    sm_scale = 1.0 / (head_dim ** 0.5)
    
    print("\n[1] Baseline 3: Flash Attention v2 Triton (æ— RoPEèåˆ)")
    try:
        # Warmup to trigger autotune
        for _ in range(10):
            _ = flash_attn_v2_triton(q, k, v, causal, sm_scale, False)
        torch.cuda.synchronize()
        
        print("  âœ“ Kernel compiled successfully")
        # Note: Getting actual register count and occupancy requires nsight compute
        print("  âš ï¸  Use `nsys profile` or `ncu` to get detailed metrics:")
        print(f"      ncu --metrics sm__warps_active.avg.pct_of_peak python -c 'your_code'")
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
    
    print("\n[2] Fused RoPE: Triton (RoPEèåˆ)")
    try:
        # Warmup to trigger autotune
        for _ in range(10):
            _ = fused_rope_attn(q, k, v, causal, sm_scale, freqs_cos, freqs_sin, False)
        torch.cuda.synchronize()
        
        print("  âœ“ Kernel compiled successfully")
        print("  âš ï¸  Use `nsys profile` or `ncu` to get detailed metrics")
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
    
    # ç†è®ºåˆ†æ
    print(f"\n[3] ç†è®ºåˆ†æ")
    print(f"  åºåˆ—é•¿åº¦: {seq_len}")
    print(f"  FLOPs (causal): {2 * batch * n_heads * seq_len * seq_len * head_dim * 0.5 / 1e9:.2f} GFLOPs")
    print(f"  Memory (Q+K+V): {3 * batch * n_heads * seq_len * head_dim * 2 / 1024**2:.2f} MB")
    print(f"  Memory (O): {batch * n_heads * seq_len * head_dim * 2 / 1024**2:.2f} MB")
    print(f"  Total Memory: {4 * batch * n_heads * seq_len * head_dim * 2 / 1024**2:.2f} MB")
    
    # L2 cache size (H200 has 60MB L2)
    l2_cache_mb = 60
    total_mem_mb = 4 * batch * n_heads * seq_len * head_dim * 2 / 1024**2
    if total_mem_mb > l2_cache_mb:
        print(f"\n  âš ï¸  æ•°æ®é‡ ({total_mem_mb:.2f} MB) è¶…è¿‡ L2 cache ({l2_cache_mb} MB)")
        print(f"      é•¿åºåˆ—æ—¶ä¼šé¢‘ç¹è®¿é—® HBMï¼Œbandwidth æˆä¸ºç“¶é¢ˆ")
    
    # Register pressureä¼°è®¡
    print(f"\n[4] Register Pressure ä¼°è®¡")
    print(f"  Fused RoPE éœ€è¦é¢å¤–å­˜å‚¨:")
    print(f"    - cos/sin frequencies: ~{seq_len * head_dim // 2 * 4 / 1024:.2f} KB per block")
    print(f"    - Rotated Q/K: å¢åŠ ä¸­é—´ç»“æœå¯„å­˜å™¨ä½¿ç”¨")
    print(f"    - ä¼°è®¡å¢åŠ  20-30% å¯„å­˜å™¨ä½¿ç”¨")
    
    if seq_len >= 8192:
        print(f"\n  ğŸ’¡ å»ºè®®:")
        print(f"    1. å‡å° BLOCK_M/BLOCK_N ä»¥é™ä½å¯„å­˜å™¨å‹åŠ›")
        print(f"    2. ä½¿ç”¨ multi-stage pipeline ä¼˜åŒ–å†…å­˜è®¿é—®")
        print(f"    3. è€ƒè™‘é•¿åºåˆ—æ—¶å›é€€åˆ°éèåˆç‰ˆæœ¬")


def run_diagnosis():
    """è¿è¡Œå®Œæ•´è¯Šæ–­"""
    print("="*80)
    print("Fused RoPE Kernel æ€§èƒ½è¯Šæ–­å·¥å…·")
    print("="*80)
    
    # è¯Šæ–­ä¸åŒåºåˆ—é•¿åº¦
    test_configs = [
        (512, 128, 4, 32),    # çŸ­åºåˆ—ï¼šæ€§èƒ½å¥½
        (2048, 128, 2, 32),   # ä¸­ç­‰åºåˆ—ï¼šæ€§èƒ½å¥½
        (8192, 128, 1, 32),   # é•¿åºåˆ—ï¼šå¼€å§‹é€€åŒ–
        (32768, 128, 1, 16),  # è¶…é•¿åºåˆ—ï¼šä¸¥é‡é€€åŒ–
    ]
    
    for seq_len, head_dim, batch, n_heads in test_configs:
        diagnose_kernel_config(seq_len, head_dim, batch, n_heads)
    
    print(f"\n{'='*80}")
    print("è¯Šæ–­å®Œæˆ")
    print(f"{'='*80}")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("1. è¿è¡Œ nsight compute è·å–è¯¦ç»† metrics:")
    print("   ncu --set full -o profile python bench_compare.py")
    print("\n2. æŸ¥çœ‹å…³é”®æŒ‡æ ‡:")
    print("   - sm__warps_active.avg.pct_of_peak (Occupancy)")
    print("   - l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum (Global Load)")
    print("   - smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct (Load Efficiency)")


if __name__ == "__main__":
    run_diagnosis()

